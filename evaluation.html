<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Evaluation &mdash; grand-challenge.org  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithms" href="algorithms.html" />
    <link rel="prev" title="Development" href="development.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> grand-challenge.org
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#evaluation-container-requirements">Evaluation Container Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#input">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="#entrypoint">Entrypoint</a></li>
<li class="toctree-l3"><a class="reference internal" href="#errors">Errors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#output">Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#evaluation-options">Evaluation Options</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-grandchallenge.evaluation.templatetags.evaluation_extras">Template Tags</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="components.html">Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="workstations.html">Workstations</a></li>
<li class="toctree-l1"><a class="reference internal" href="reader-studies.html">Reader Studies</a></li>
<li class="toctree-l1"><a class="reference internal" href="design.html">Design decisions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">grand-challenge.org</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Evaluation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/evaluation.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="evaluation">
<h1>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline"></a></h1>
<p>grand-challenge.org has a system for automatically evaluating new submissions.
Challenge administrators upload their own Docker containers that will be
executed by Celery workers when a new submission in uploaded by a participant.</p>
<section id="evaluation-container-requirements">
<h2>Evaluation Container Requirements<a class="headerlink" href="#evaluation-container-requirements" title="Permalink to this headline"></a></h2>
<p>The evaluation container must contain everything that is needed to perform the
evaluation on a new submission. This includes the reference standard, and the
code that will execute the evaluation on the new submission. An instance of the
evaluation container image is created for each submission.</p>
<section id="input">
<h3>Input<a class="headerlink" href="#input" title="Permalink to this headline"></a></h3>
<p>The participants submission will be extracted and mounted as a docker volume
on <cite>/input/</cite>.</p>
</section>
<section id="entrypoint">
<h3>Entrypoint<a class="headerlink" href="#entrypoint" title="Permalink to this headline"></a></h3>
<p>The container will be run with the default arguments, so the entrypoint must
by default produce an evaluation for the data that will reside on <cite>/input/</cite>.
The container is responsible for loading all of the data, handling incorrect
filenames, incomplete submissions, duplicate folders, etc.</p>
</section>
<section id="errors">
<h3>Errors<a class="headerlink" href="#errors" title="Permalink to this headline"></a></h3>
<p>If there is an error in the evaluation process grand-challenge.org will parse
<cite>stderr</cite> and return the last non-empty line to the user. If your evaluation
script is in Python the best practice is to raise an exception and the message
will then be passed to the user, eg</p>
<blockquote>
<div><p>raise AttributeError(‘Expected to find 10 images, you submitted 5’)</p>
</div></blockquote>
</section>
<section id="output">
<h3>Output<a class="headerlink" href="#output" title="Permalink to this headline"></a></h3>
<p>The container must produce the file <cite>/output/metrics.json</cite>. The structure
within must be valid json (ie. loadable with <cite>json.loads()</cite>) and will be stored
as a result in the database. The challenge administrator is free to define what
metrics are included. We recommend storing results in two objects - <cite>case</cite> for
the scores on individual cases (eg, scans), and <cite>aggregates</cite> for when there
is one number per evaluation. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;case&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;dicecoefficient&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="mf">0.6461774875144065</span><span class="p">,</span>
      <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="mf">0.7250400040547097</span><span class="p">,</span>
      <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="mf">0.6747092236948878</span><span class="p">,</span>
      <span class="s2">&quot;3&quot;</span><span class="p">:</span> <span class="mf">0.6452332692745784</span><span class="p">,</span>
      <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="mf">0.6839602948067993</span><span class="p">,</span>
      <span class="s2">&quot;5&quot;</span><span class="p">:</span> <span class="mf">0.6817807628480707</span><span class="p">,</span>
      <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="mf">0.4715406247268339</span><span class="p">,</span>
      <span class="s2">&quot;7&quot;</span><span class="p">:</span> <span class="mf">0.5988810496224731</span><span class="p">,</span>
      <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="mf">0.5475856316815167</span><span class="p">,</span>
      <span class="s2">&quot;9&quot;</span><span class="p">:</span> <span class="mf">0.32923801642370615</span>
    <span class="p">},</span>
    <span class="s2">&quot;jaccardcoefficient&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="mf">0.47729852440408627</span><span class="p">,</span>
      <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="mf">0.5686766693547471</span><span class="p">,</span>
      <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="mf">0.5091027839007266</span><span class="p">,</span>
      <span class="s2">&quot;3&quot;</span><span class="p">:</span> <span class="mf">0.47626890640360103</span><span class="p">,</span>
      <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="mf">0.5197109875240358</span><span class="p">,</span>
      <span class="s2">&quot;5&quot;</span><span class="p">:</span> <span class="mf">0.5171983108978807</span><span class="p">,</span>
      <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="mf">0.30850713624139353</span><span class="p">,</span>
      <span class="s2">&quot;7&quot;</span><span class="p">:</span> <span class="mf">0.4274305543159676</span><span class="p">,</span>
      <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="mf">0.3770174983296798</span><span class="p">,</span>
      <span class="s2">&quot;9&quot;</span><span class="p">:</span> <span class="mf">0.1970585994056237</span>
    <span class="p">},</span>
    <span class="s2">&quot;alg_fname&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2296.1199810886.7.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.276.0.28.3.0.14.4.0.20090213134050413.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.276.0.28.3.0.14.4.0.20090213134114792.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;3&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2004.1131987870.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2296.1199810941.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;5&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.4400.1131982359.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="s2">&quot;1.3.12.2.1107.5.1.4.50585.4.0.7023259421321855.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;7&quot;</span><span class="p">:</span> <span class="s2">&quot;1.0.000.000000.0.00.0.0000000000.0000.0000000000.000.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.392.200036.9116.2.2.2.1762676169.1080882991.2256.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;9&quot;</span><span class="p">:</span> <span class="s2">&quot;2.16.840.1.113669.632.21.3825556854.538251028.390606191418956020.mhd&quot;</span>
    <span class="p">},</span>
    <span class="s2">&quot;gt_fname&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2296.1199810886.7.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;1&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.276.0.28.3.0.14.4.0.20090213134050413.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.276.0.28.3.0.14.4.0.20090213134114792.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;3&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2004.1131987870.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.2296.1199810941.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;5&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.840.113704.1.111.4400.1131982359.11.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="s2">&quot;1.3.12.2.1107.5.1.4.50585.4.0.7023259421321855.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;7&quot;</span><span class="p">:</span> <span class="s2">&quot;1.0.000.000000.0.00.0.0000000000.0000.0000000000.000.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="s2">&quot;1.2.392.200036.9116.2.2.2.1762676169.1080882991.2256.mhd&quot;</span><span class="p">,</span>
      <span class="s2">&quot;9&quot;</span><span class="p">:</span> <span class="s2">&quot;2.16.840.1.113669.632.21.3825556854.538251028.390606191418956020.mhd&quot;</span>
    <span class="p">}</span>
  <span class="p">},</span>
  <span class="s2">&quot;aggregates&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;dicecoefficient_mean&quot;</span><span class="p">:</span> <span class="mf">0.6004146364647982</span><span class="p">,</span>
    <span class="s2">&quot;dicecoefficient_std&quot;</span><span class="p">:</span> <span class="mf">0.12096508479974993</span><span class="p">,</span>
    <span class="s2">&quot;dicecoefficient_min&quot;</span><span class="p">:</span> <span class="mf">0.32923801642370615</span><span class="p">,</span>
    <span class="s2">&quot;dicecoefficient_max&quot;</span><span class="p">:</span> <span class="mf">0.7250400040547097</span><span class="p">,</span>
    <span class="s2">&quot;jaccardcoefficient_mean&quot;</span><span class="p">:</span> <span class="mf">0.4378269970777743</span><span class="p">,</span>
    <span class="s2">&quot;jaccardcoefficient_std&quot;</span><span class="p">:</span> <span class="mf">0.11389145837530869</span><span class="p">,</span>
    <span class="s2">&quot;jaccardcoefficient_min&quot;</span><span class="p">:</span> <span class="mf">0.1970585994056237</span><span class="p">,</span>
    <span class="s2">&quot;jaccardcoefficient_max&quot;</span><span class="p">:</span> <span class="mf">0.5686766693547471</span><span class="p">,</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="evaluation-options">
<h3>Evaluation Options<a class="headerlink" href="#evaluation-options" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grandchallenge.evaluation.models.</span></span><span class="sig-name descname"><span class="pre">Phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">created</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modified</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">challenge</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">archive</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slug</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_title</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_jsonpath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_error_jsonpath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_default_sort</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_decimal_places</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_results_columns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_method_choice</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">result_display_choice</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">creator_must_be_verified</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submission_kind</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_submission_comments</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_submission_comments</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_file_choice</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_file_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_file_help_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_supplementary_file_link</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_url_choice</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_url_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supplementary_url_help_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_supplementary_url</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submission_limit</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submission_limit_period</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submissions_open_at</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submissions_close_at</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">submission_page_html</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auto_publish_new_results</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_all_metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm_time_limit</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">public</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>id</strong> (<em>UUIDField</em>) – Id</p></li>
<li><p><strong>created</strong> (<em>DateTimeField</em>) – Created</p></li>
<li><p><strong>modified</strong> (<em>DateTimeField</em>) – Modified</p></li>
<li><p><strong>challenge</strong> (ForeignKey to <code class="xref py py-class docutils literal notranslate"><span class="pre">Challenge</span></code>) – Challenge</p></li>
<li><p><strong>archive</strong> (ForeignKey to <code class="xref py py-class docutils literal notranslate"><span class="pre">Archive</span></code>) – Archive. Which archive should be used as the source dataset for this phase?</p></li>
<li><p><strong>title</strong> (<em>CharField</em>) – Title. The title of this phase.</p></li>
<li><p><strong>slug</strong> (<em>AutoSlugField</em>) – Slug</p></li>
<li><p><strong>score_title</strong> (<em>CharField</em>) – Score title. The name that will be displayed for the scores column, for instance: Score (log-loss)</p></li>
<li><p><strong>score_jsonpath</strong> (<em>CharField</em>) – Score jsonpath. The jsonpath of the field in metrics.json that will be used for the overall scores on the results page. See <a class="reference external" href="http://goessner.net/articles/JsonPath/">http://goessner.net/articles/JsonPath/</a> for syntax. For example: dice.mean</p></li>
<li><p><strong>score_error_jsonpath</strong> (<em>CharField</em>) – Score error jsonpath. The jsonpath for the field in metrics.json that contains the error of the score, eg: dice.std</p></li>
<li><p><strong>score_default_sort</strong> (<em>CharField</em>) – Score default sort. The default sorting to use for the scores on the results page.</p></li>
<li><p><strong>score_decimal_places</strong> (<em>PositiveSmallIntegerField</em>) – Score decimal places. The number of decimal places to display for the score</p></li>
<li><p><strong>extra_results_columns</strong> (<em>JSONField</em>) – Extra results columns. A JSON object that contains the extra columns from metrics.json that will be displayed on the results page.</p></li>
<li><p><strong>scoring_method_choice</strong> (<em>CharField</em>) – Scoring method choice. How should the rank of each result be calculated?</p></li>
<li><p><strong>result_display_choice</strong> (<em>CharField</em>) – Result display choice. Which results should be displayed on the leaderboard?</p></li>
<li><p><strong>creator_must_be_verified</strong> (<em>BooleanField</em>) – Creator must be verified. If True, only participants with verified accounts can make submissions to this phase</p></li>
<li><p><strong>submission_kind</strong> (<em>PositiveSmallIntegerField</em>) – Submission kind. Should participants submit a .csv/.zip file of predictions, or an algorithm?</p></li>
<li><p><strong>allow_submission_comments</strong> (<em>BooleanField</em>) – Allow submission comments. Allow users to submit comments as part of their submission.</p></li>
<li><p><strong>display_submission_comments</strong> (<em>BooleanField</em>) – Display submission comments. If true, submission comments are shown on the results page.</p></li>
<li><p><strong>supplementary_file_choice</strong> (<em>CharField</em>) – Supplementary file choice. Show a supplementary file field on the submissions page so that users can upload an additional file along with their predictions file as part of their submission (eg, include a pdf description of their method). Off turns this feature off, Optional means that including the file is optional for the user, Required means that the user must upload a supplementary file.</p></li>
<li><p><strong>supplementary_file_label</strong> (<em>CharField</em>) – Supplementary file label. The label that will be used on the submission and results page for the supplementary file. For example: Algorithm Description.</p></li>
<li><p><strong>supplementary_file_help_text</strong> (<em>CharField</em>) – Supplementary file help text. The help text to include on the submissions page to describe the submissions file. Eg: “A PDF description of the method.”.</p></li>
<li><p><strong>show_supplementary_file_link</strong> (<em>BooleanField</em>) – Show supplementary file link. Show a link to download the supplementary file on the results page.</p></li>
<li><p><strong>supplementary_url_choice</strong> (<em>CharField</em>) – Supplementary url choice. Show a supplementary url field on the submission page so that users can submit a link to a publication that corresponds to their submission. Off turns this feature off, Optional means that including the url is optional for the user, Required means that the user must provide an url.</p></li>
<li><p><strong>supplementary_url_label</strong> (<em>CharField</em>) – Supplementary url label. The label that will be used on the submission and results page for the supplementary url. For example: Publication.</p></li>
<li><p><strong>supplementary_url_help_text</strong> (<em>CharField</em>) – Supplementary url help text. The help text to include on the submissions page to describe the submissions url. Eg: “A link to your publication.”.</p></li>
<li><p><strong>show_supplementary_url</strong> (<em>BooleanField</em>) – Show supplementary url. Show a link to the supplementary url on the results page</p></li>
<li><p><strong>submission_limit</strong> (<em>PositiveIntegerField</em>) – Submission limit. The limit on the number of times that a user can make a submission over the submission limit period. Set this to 0 to close submissions for this phase.</p></li>
<li><p><strong>submission_limit_period</strong> (<em>PositiveSmallIntegerField</em>) – Submission limit period. The number of days to consider for the submission limit period. If this is set to 1, then the submission limit is applied over the previous day. If it is set to 365, then the submission limit is applied over the previous year. If the value is not set, then the limit is applied over all time.</p></li>
<li><p><strong>submissions_open_at</strong> (<em>DateTimeField</em>) – Submissions open at. If set, participants will not be able to make submissions to this phase before this time.</p></li>
<li><p><strong>submissions_close_at</strong> (<em>DateTimeField</em>) – Submissions close at. If set, participants will not be able to make submissions to this phase after this time.</p></li>
<li><p><strong>submission_page_html</strong> (<em>TextField</em>) – Submission page html. HTML to include on the submission page for this challenge.</p></li>
<li><p><strong>auto_publish_new_results</strong> (<em>BooleanField</em>) – Auto publish new results. If true, new results are automatically made public. If false, the challenge administrator must manually publish each new result.</p></li>
<li><p><strong>display_all_metrics</strong> (<em>BooleanField</em>) – Display all metrics. Should all of the metrics be displayed on the Result detail page?</p></li>
<li><p><strong>algorithm_time_limit</strong> (<em>PositiveSmallIntegerField</em>) – Algorithm time limit. Time limit for inference jobs in seconds</p></li>
<li><p><strong>public</strong> (<em>BooleanField</em>) – Public. Uncheck this box to hide this phase’s submission page and leaderboard from participants. Participants will then no longer have access to their previous submissions and evaluations from this phase if they exist, and they will no longer see the respective submit and leaderboard tabs for this phase. For you as admin these tabs remain visible.Note that hiding a phase is only possible if submissions for this phase are closed for participants.</p></li>
<li><p><strong>inputs</strong> (<em>ManyToManyField</em>) – Inputs</p></li>
<li><p><strong>outputs</strong> (<em>ManyToManyField</em>) – Outputs</p></li>
<li><p><strong>algorithm_inputs</strong> (<em>ManyToManyField</em>) – Algorithm inputs. The input interfaces that the algorithms for this phase must use</p></li>
<li><p><strong>algorithm_outputs</strong> (<em>ManyToManyField</em>) – Algorithm outputs. The output interfaces that the algorithms for this phase must use</p></li>
<li><p><strong>actor_actions</strong> (<em>GenericRelation</em>) – Actor actions</p></li>
<li><p><strong>target_actions</strong> (<em>GenericRelation</em>) – Target actions</p></li>
<li><p><strong>action_object_actions</strong> (<em>GenericRelation</em>) – Action object actions</p></li>
</ul>
</dd>
</dl>
<dl class="py exception">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.DoesNotExist">
<em class="property"><span class="pre">exception</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">DoesNotExist</span></span><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.DoesNotExist" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.MultipleObjectsReturned">
<em class="property"><span class="pre">exception</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">MultipleObjectsReturned</span></span><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.MultipleObjectsReturned" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.SubmissionKind">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">SubmissionKind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase.SubmissionKind"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.SubmissionKind" title="Permalink to this definition"></a></dt>
<dd><p>An enumeration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.clean">
<span class="sig-name descname"><span class="pre">clean</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase.clean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.clean" title="Permalink to this definition"></a></dt>
<dd><p>Hook for doing any extra model-wide validation after clean() has been
called on every field by self.clean_fields. Any ValidationError raised
by this method will not be associated with a particular field; it will
have a special-case association with the field defined by NON_FIELD_ERRORS.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.get_next_submission">
<span class="sig-name descname"><span class="pre">get_next_submission</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">user</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase.get_next_submission"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.get_next_submission" title="Permalink to this definition"></a></dt>
<dd><p>Determines the number of submissions left for the user,
and when they can next submit.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grandchallenge.evaluation.models.Phase.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/models.html#Phase.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.models.Phase.save" title="Permalink to this definition"></a></dt>
<dd><p>Save the current instance. Override this in a subclass if you want to
control the saving process.</p>
<p>The ‘force_insert’ and ‘force_update’ parameters can be used to insist
that the “save” must be an SQL insert or update (or equivalent for
non-SQL backends), respectively. Normally, they should not be set.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="module-grandchallenge.evaluation.templatetags.evaluation_extras">
<span id="template-tags"></span><h2>Template Tags<a class="headerlink" href="#module-grandchallenge.evaluation.templatetags.evaluation_extras" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="grandchallenge.evaluation.templatetags.evaluation_extras.get_jsonpath">
<span class="sig-prename descclassname"><span class="pre">grandchallenge.evaluation.templatetags.evaluation_extras.</span></span><span class="sig-name descname"><span class="pre">get_jsonpath</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jsonpath</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/grandchallenge/evaluation/templatetags/evaluation_extras.html#get_jsonpath"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grandchallenge.evaluation.templatetags.evaluation_extras.get_jsonpath" title="Permalink to this definition"></a></dt>
<dd><p>Gets a value from a dictionary based on a jsonpath. It will only return
one result, and if a key does not exist it will return an empty string as
template tags should not raise errors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obj</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>) – The dictionary to query</p></li>
<li><p><strong>jsonpath</strong> – The path to the object (singular)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The most relevant object in the dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="development.html" class="btn btn-neutral float-left" title="Development" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="algorithms.html" class="btn btn-neutral float-right" title="Algorithms" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, James Meakin.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>